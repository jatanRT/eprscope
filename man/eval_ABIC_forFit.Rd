% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eval_ABIC_forFit.R
\name{eval_ABIC_forFit}
\alias{eval_ABIC_forFit}
\title{General Ranking of Models/Fits Using the AIC and BIC Metrics}
\usage{
eval_ABIC_forFit(data.fit, residuals = NULL, k, rs.prob.distro = "auto")
}
\arguments{
\item{data.fit}{Data frame object, usually containing variables/columns like \code{experiment},
\code{fit(ted)}/\code{predicted} as well as \code{residuals}/\code{errors}. If the latter is missing
(see the argument \code{residuals} below) one can easily create/calculate the variable/column
as a difference between the experimental and fitted/predicted values.}

\item{residuals}{Character string, pointing to variable/column header with residuals/errors, depending
on the \code{data.fit} argument (usually \code{residuals = "Residuals"} or \code{residuals = "errors"}).
\strong{Default}: \code{residuals = NULL}.}

\item{k}{Numeric value identical to number of parameters used in your model/fit
(see e.g. \code{Examples} in the \code{\link{eval_kinR_EPR_modelFit}} where \code{k = 2}).}

\item{rs.prob.distro}{Character string, corresponding to proposed residuals/errors probability distribution.
If set to \strong{default} (\code{rs.prob.distro = "auto"}), it automatically decides which distribution
(Normal/Gaussian or Student's t-distribution) fits the best to residuals/errors based on the implemented
AIC and BIC calculations. This is particularly suitable for the situation when residual analysis detects
heavier tails (see e.g. \code{Example} in \code{\link{eval_sim_EPR_isoFit}}) and one is not quite
sure of the corresponding probability distribution. Otherwise, the argument may also specify individual
distributions like: \code{rs.prob.distro = "normal"}, \code{"Gaussian"}, \code{"Student"} or
\code{"t-distribution"} (\code{"t-distro"}).}
}
\value{
Function returns a list with the following components:
  \describe{
  \item{abic.vec}{A numeric vector containing the values of estimated AIC and BIC, respectively.}
  \item{message}{Sentence (Message), describing the residuals/errors probability distribution,
        that has been proposed for the AIC and BIC calculation (see also the \code{rs.prob.distro}
        argument).}
  }
}
\description{
When comparing different (simulation) fits for the same experimental data (see
  \code{\link{eval_sim_EPR_isoFit}}, \code{\link{eval_kinR_EPR_modelFit}}, \code{\link{eval_kinR_Eyring_GHS}}
  or \code{\link{smooth_EPR_Spec_by_npreg}}), the fits can be scored/ranked by different
  metrics (e.g. minimum sum of residual squares or standard deviation of residuals), including
  Akaike and Bayesian Information Criteria (\code{\link[stats]{AIC}} and BIC, respectively).
  These are also applied for the best model selection in machine learning (refer to e.g.
  \href{https://www.modernstatisticswithr.com/mlchapter.html}{Predictive Modelling and Machine Learning} or
  \href{https://www.louisaslett.com/StatML/notes/error-estimation-and-model-selection.html#ref-yang05}{Error Estimation and Model Selection}).
  As described in details, both metrics depends on maximum logarithmic likelihood (based on residuals calculation)
  to the same data. \strong{The smaller the (negative) AIC or BIC, the better the model/fit.}
}
\details{
Estimation of model errors, that model/fit makes in respect to our (experimental) data, becomes
  one of the most consequential aspects of a statistical (machine learning) analysis. Often, different
  modelling/fitting approaches are used, with the attempt to identify or select the best model/fit. Therefore,
  for such purpose, one tries to minimize the errors/residuals more and more with each model. Or to put it another way,
  \strong{there is an information loss when the model/fit approximates the reality} and a good model minimizes
  those losses. The evaluation of AIC and BIC actually approaches the problem from the other site,
  because it uses the technique called \strong{maximum likelihood estimate (MLE)}. The idea is to maximize the chance
  that each observation in the sample follows a pre-selected distribution with specific
  set of parameters (corresponding to a model/fit). For practical reasons a logarithmic likelihood
  (or log-likelihood,\eqn{LL}) is used, and the formulae for both criteria read:
  \deqn{AIC = -2\,LL + 2\,k + (2\,k\,(k + 1)\,/\,(N - k -1))}
  and
  \deqn{BIC = -2\,LL + k\,ln(N)}
  where \eqn{k} and \eqn{N} correspond to number of (model/fit) parameters and number of observations, respectively.
  The 3rd term in the \eqn{AIC} definition represents the correction for small sample/observation ensemble, which
  for high number of observations becomes very small (and can be neglected,
  see e.g. Burnham and Anderson (2004) or Kumar (2023) in the \code{References}). For example, for EPR simulation
  fit with 2048 points and 8 parameters it equals to \eqn{16 \cdot 9\,/\,2039 \approx 0.0706}. However, for
  radical kinetic measurements with 42 EPR spectra and 3 parameters, the 3rd term results
  in \eqn{6 \cdot 4\,/\,38 \approx 0.6316}.

  \strong{The original MLE/\eqn{LL} calculation is based on the model. Nevertheless, such computation can be quite often
  impractical or even impossible to perform.} To overcome this difficulty, the formulae for both criteria
  use a \strong{standard assumption that the model and the data residuals/errors are identically distributed.}
  Therefore, \strong{the residuals/errors are applied as a proxy for the MLE/\eqn{LL}} (see e.g. Rossi et al. (2020)
  and Kumar (2023) in the \code{References}). Evaluation of the latter, in the actual function, proceeds through \code{sum}
  of the \code{\link[stats:Normal]{stats::dnorm}} (for the normal/Gaussian distribution)
  and of the \code{\link[stats:TDist]{stats::dt}} (for the Student's t-distribution), using the \code{log = TRUE}
  option. For t-distribution the \code{df}/\eqn{\nu} parameter is unknown, therefore it is optimized
  by the above-described \eqn{LL} as well as by the \code{\link[stats]{optimize}} function. Both probability distributions
  are included in the function because not always the residuals/errors follow the normal one. Sometimes, heavier tails
  may appear, e.g. for EPR simulation fits (please, refer to the \code{Examples} in the \code{\link{eval_sim_EPR_isoFit}}).
  Consequently, the function may automatically (see the argument \code{rs.prob.distro}) decide which distribution
  fits the residuals/errors the best, based on the lower AIC, BIC values.
  \strong{It is recommended to evaluate/apply both information criteria}. The AIC tends to favor a more complex model
  (over a simpler one) and thus suggests to "overfit" the data, whereas the BIC is in favor of simpler models because
  it possesses a stronger penalty (\eqn{k\,ln(N)}) for complex models than AIC (\eqn{2\,k},see e.g. Fabozzi et al. (2014)
  and Zhang Y, Meng G (2023) in the \code{References}).
}
\examples{
\dontrun{
## to decide which probability distribution fits
## the best to residuals/errors
calc.abic.list.01 <-
  eval_ABIC_forFit(
    data.fit = triaryl_model_kin_fit_01$df,
    residuals = "residuals",
    k = 2,
    rs.prob.distro = "auto"
 )
#
## AIC and BIC values
calc.abic.list.01$abic
#
## ...and the corresponding message
calc.abic.list.01$message
#
## calculation of AIC and BIC, taking into
## account the Student's t-distribution:
calc.abic.list.01 <-
  eval_ABIC_forFit(
    data.fit = best.sim.fit.df,
    residuals = "Errors",
    k = 8,
    rs.prob.distro = "t-distro"
  )
#
## for additional applications please,
## refer to the Examples in `eval_sim_EPR_isoFit()`
## or `eval_kinR_EPR_modelFit()`
#
}


}
\references{
Fabozzi FJ, Focardi FM, Rachev ST, Arshanapalli BG (2014). \emph{The Basics of Financial Econometrics:
  Tools, Concepts, and Asset Management Applications (Appendix E)}, John Wiley and Sons, Inc. ISBN 978-1-118-57320-4,
  \url{https://onlinelibrary.wiley.com/doi/book/10.1002/9781118856406}.

  Soch J et al. (2024). StatProofBook/StatProofBook.github.io: \emph{The Book of Statistical Proofs (Version 2023).},
  \url{https://statproofbook.github.io/}, \url{https://doi.org/10.5281/ZENODO.4305949}.

  Burnham KP, Anderson DR (2004). "Multimodel Interference: Understanding AIC and BIC in Model Selection",
  \emph{Sociol. Methods  Res.}, \strong{33}(2), 261-304, \url{https://doi.org/10.1177/0049124104268644}.

  Thulin M (2025). \emph{Modern Statistics with R: From Wrangling and Exploring Data to Inference
  and Predictive Modeling}, 2nd edition (Version 2.0.2), CRC Press and Taylor and Francis Group, LLC.
  ISBN 978-1-032-51244-0, \url{https://www.modernstatisticswithr.com/}.

  Zhang Y, Meng G (2023). "Simulation of an Adaptive Model Based on AIC and BIC ARIMA Predictions",
  \emph{J. Phys.: Conf. Ser.}, \strong{2449}, 012027-7, \url{https://doi.org/10.1088/1742-6596/2449/1/012027}.

  Svetunkov I (2022). \emph{Statistics for Business Analytics}, Version 2025,
  \url{https://openforecast.org/sba/}.

  Rossi R, Murari R, Gaudio P, Gelfusa M (2020). "Upgrading Model Selection Criteria with Goodness
  of Fit Tests for Practical Applications", \emph{Entropy}, \strong{22}(4), 447-13,
  \url{https://doi.org/10.3390/e22040447}.

  Hyndman RJ (2013). "Facts and Fallacies of the AIC", \url{https://robjhyndman.com/hyndsight/aic/}.

  Kumar A (2023). "AIC and BIC for Selecting Regression Models: Formula, Examples",
  \url{https://vitalflux.com/aic-vs-bic-for-regression-models-formula-examples/#comments}.
}
\seealso{
Other Simulations and Optimization: 
\code{\link{eval_sim_EPR_iso}()},
\code{\link{eval_sim_EPR_isoFit}()},
\code{\link{eval_sim_EPR_iso_combo}()},
\code{\link{optim_for_EPR_fitness}()},
\code{\link{quantify_EPR_Sim_series}()},
\code{\link{smooth_EPR_Spec_by_npreg}()}
}
\concept{Simulations and Optimization}
