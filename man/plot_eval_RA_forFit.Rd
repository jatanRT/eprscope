% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plot_eval_RA_forFit.R
\name{plot_eval_RA_forFit}
\alias{plot_eval_RA_forFit}
\title{General Diagnostics for Models/Fits by Simple Residual Analysis}
\usage{
plot_eval_RA_forFit(
  data.fit,
  residuals = NULL,
  fitted = NULL,
  resid.method.smooth = "loess",
  resid.xlab = NULL,
  k,
  level.cnfd = 0.95
)
}
\arguments{
\item{data.fit}{Data frame object, usually containing variables/columns like \code{experiment},
\code{fit(ted)}/\code{predicted} as well as \code{residuals}/\code{errors}. If the latter is missing
(see the argument \code{residuals} below) one can easily create/calculate the variable/column
as a difference between the experimental and fitted/predicted values.}

\item{residuals}{Character string, pointing to variable/column header with residuals/errors, depending
on the \code{data.fit} argument (usually \code{residuals = "Residuals"} or \code{residuals = "errors"}).
\strong{Default}: \code{residuals = NULL}.}

\item{fitted}{Character string, pointing to variable/column header with (model) fitted/predicted values, depending
on the \code{data.fit} argument (usually \code{fitted = "fit(ted)"}, \code{fitted = "predicted"}
or \code{fitted = "theory"}). \strong{Default}: \code{fitted = NULL}.}

\item{resid.method.smooth}{Character string, corresponding to smoothing method (function) to follow
the trends of residual plot (Residuals \emph{vs} Fitted/Predicted values).
\strong{Default}: \code{resid.method.smooth = "loess"} ("local regression" or "locally estimated
scatter plot smoothing"). Additional methods like \code{"lm"} (linear method/model)
or \code{"glm"} can be applied as well. For details and if \code{resid.method = NULL} (related to automatic
method selection, based on number of points), please consult the \code{\link[ggplot2]{geom_smooth}} for documentation.}

\item{resid.xlab}{Character string, pointing to \eqn{x}-axis label for residual plot
(Residuals \emph{vs} Fitted/Predicted values). \strong{Default}: \code{resid.xlab = NULL}, actually
corresponding to \code{"Fitted or Simulated Values"}. Customized labels like \code{"Kinetic Model Fit (qvar)"}
or \code{"Quantity (unit)"} can be applied as well.}

\item{k}{Numeric value identical to number of parameters used for the model/fit
(see e.g. \code{Examples} in the \code{\link{eval_kinR_EPR_modelFit}} where \code{k = 2}).}

\item{level.cnfd}{Numeric value, identical with level of the applied confidence interval
(see also the \code{se} argument). \strong{Default}: \code{level.cnfd = 0.95}.}
}
\value{
A List, consisting of the following elements is returned:
  \describe{
  \item{df}{Original \code{data.fit} data frame object, if additional processing/analysis
  is required (see the \code{Details} or to perform Residuals \emph{vs} Observation Order to verify
  the assumption that the residuals are independent from one another).}
  \item{plot.rqq()}{Function, related to visual \strong{r}esidual
  \strong{a}nalysis), returning two main plots: Residuals \emph{vs} Predicted/Fitted Values from
  the model/fit or simulation, and the Q-Q plot: Sample Quantiles \emph{vs} Theoretical Quantiles,
  where the theoretical ones correspond to a specific distribution (normal/Student's/Cauchy).
  Therefore, function has the following arguments:
  \enumerate{
  \item \code{residuals.distro = c("norm","t","cauchy")} (\strong{default}: \code{residuals.distro = "norm"})

  \item \code{confidence = level.cnfd} (\strong{default}: \code{confidence = level.cnfd = 0.95})

  \item \code{...} additional arguments/parameters for the distro/distribution like \code{df} (degrees of freedom)
  for the Student's t one.
   }
  }
  \item{plot.histDens}{Ggplot2 object, showing the \strong{hist}ogram
  and the scaled probability \strong{dens}ity function for residuals. The corresponding residuals
  mean value and the median are identified by vertical lines.}
  \item{sd}{\strong{S}tandard \strong{d}eviation of residuals (or residual standard error (RSE))
  for the model/fit defined as:
  \deqn{\sqrt{\sum_i (y_i - y_{i,\text{fit/model}})^2\,/\,(N - k - 1)}}
  where \eqn{N} is the number of observations/points (see the \code{data.fit} argument) and \eqn{k}
  is the number of optimized parameters (see the argument \code{k}). Therefore, the smaller
  the \code{sd}, the better the fit, when comparing different models/fits.}
  }
}
\description{
Three visual diagnostic tools (based on the \href{https://ggplot2.tidyverse.org/}{\code{{ggplot2}}}
  package) and one metric (standard deviation of residuals) are applied to evaluate the appropriateness as well as to compare
  different models/fits. 1. The first plot represents the Residuals \emph{vs} Fitted/Simulated Values relation.
  For a decent model/fit, it will exhibit randomly scattered values around \code{0} and displays a similar
  variance over all predicted/fitted values. 2. \emph{Sample Quantiles (Residuals) vs Theoretical Quantiles} (Q-Q plot)
  shows, whether the appearance of residuals can be described by the three probability distributions:
  \code{c("norm","t","cauchy")} (i.e. Normal or Student's t or Cauchy, see also the \code{\link{eval_ABIC_forFit}} function).
  3. The latter is combined with a more detailed information about the distribution of residuals by the \strong{histogram}
  (\code{\link[ggplot2]{geom_histogram}}) as well as by the \strong{probability density} (\code{\link[ggplot2]{geom_density}},
  including the residuals \code{mean} value, and \code{median} which in ideal case equal to \code{0}).
}
\details{
Analysis of residuals is a powerful statistical technique to check whether the model/fit has adequately
  captured the information in the data (please, also refer to the \code{\link{eval_ABIC_forFit}}).
  The \eqn{i}-th residual/error (in the series) is defined as the difference between the \eqn{i}-th observed response
  value (\eqn{y_i}) and that of the predicted/fitted by the model (\eqn{\hat{y}_i} or \eqn{y_{\text{fit/model}}}):
  \deqn{e_i = y_i - \hat{y}_i = y_i - y_{\text{fit/model}}}
  One might think of residuals as "leftovers", i.e. these are the issues/items which are unexplained,
  after the model/fit has been applied. The residual analysis therefore helps us to to determine whether
  our model/fit missed an important pattern or not at all (see Chugani (2025) in the \code{References}).
  Residuals are also used in least square fitting/optimization procedures where the sum of their squares
  is to be minimized throughout the iterations (see e.g. \code{\link{eval_sim_EPR_isoFit}}
  or \code{\link{eval_kinR_EPR_modelFit}}).

  In addition to the original "raw" residuals defined above, one may come across other types,
  like \href{https://bookdown.org/mike/data_analysis/generalized-linear-models.html}{"Pearson" (or "scaled")},
  \strong{"standardized" or "studentized"}. \strong{The latter two are helpful to identify outliers},
  which are the data points that are significantly different from the rest of the data
  (though, they can be also identified by the Q-Q plot and histogram-probability density).
  For such reason the "raw" residuals (\eqn{e_i}) are divided by their standard
  deviation (\eqn{sd} see the \code{Value} below), including the the effect of leverage.
  Thus, the formula for standardized residual reads: \eqn{r_i = e_i\,/\,(sd\,\sqrt{1 - h_{ii}})},
  where the \eqn{h_{ii}} stands for the diagonal element of the "leverage" \eqn{\hat{H}} matrix
  (see e.g. \code{References} 11-13). The simple explanation of the leverage phenomenon is following
  (see e.g. Speegle D, Clair B (2021) or The Pennsylvania State University (2018) in the \code{References}).
  The fit or the regression line goes through the center of mass of the (experimental) data (\eqn{x},\eqn{y}).
  Lets assume two points \eqn{A} and \eqn{B}, where the \eqn{A} \eqn{x}-coordinate is close to the mean value
  of predictors (\eqn{mean(x)}) and the \eqn{B} possesses an extreme \eqn{x} (far from the mean value).
  Therefore, changing the \eqn{A\,(y)} will induce a small effect (low leverage) on the fit/regression line,
  whereas the \eqn{B\,(y)} change will dramatically influence the fit (high leverage).
  \strong{Both standardized and studentized residuals can be automatically calculated for linear models} like
  \code{\link[stats]{lm}} and \code{\link[stats]{glm}}, using
  the \code{\link[stats:influence.measures]{stats::rstandard}}
  and \code{\link[stats:influence.measures]{stats::rstudent}}. A very detailed analysis for linear models is provided
  by the \href{https://goodekat.github.io/ggResidpanel/}{\code{{ggResidpanel}}} package. Additionally, a series
  of diagnostic plots can be also created in the base \emph{R}, just by \code{plot(var)}, where the \code{var}
  represents the variable/object of the linear model. On the other hand, \strong{all these diagnostics are not
  available for non-linear models} like \code{\link[stats]{nls}}. Accordingly, \strong{such type of calculations
  can be provided by other packages}
  (see e.g. \href{https://cran.r-project.org/web/packages/nlstools/vignettes/vignetteJSS.pdf}{\code{{nlstools}}})
  \strong{or must be performed "manually", evaluating the numerical approximation of the gradient}
  (please, refer to the \href{https://r-forge.r-universe.dev/numDeriv/doc/manual.html#jacobian}{jacobian})
  as reported elsewhere (see Nguyen M (2020) in the \code{References}). Consequently, the calculations of standardized
  and studentized residuals are not involved in this general \code{plot_eval_RA_forFit} function. Nevertheless, users are advised
  to apply above-described options to obtain these specialized residuals or diagnostic plots for a specific model/fit
  (also refer to the \code{Value}/\code{df}) if needed.

  \strong{Considerations to support or exclude model/fit based on the residual plot.} If the residuals exhibit
  no clear pattern, like they are randomly scattered around the \code{0} with no systematic increase or decrease
  in variance, we may trust our fit with the optimized parameters. Such pattern is \strong{homoscedastic}.
  However, if one recognizes curved ((inverted-)U shape, see e.g. \code{Examples}
  in the \code{\link{eval_kinR_EPR_modelFit}}), wave or systematic increase (so called "fanning")
  or decrease ("funelling"), the model/fit is untrustworthy and one would probably search for a different (better) one.
  In particular, the curved pattern in the residual plot may indicate that a model does a poor job of fitting
  and likely, we need additional parameter(s) to describe our data properly. In the case if residuals suffer
  from unequal variance at different levels of the fitted values, the residuals are referred
  to as \strong{heteroscedastic}. In order to predict pattern of the residual plot, the corresponding relationship
  is fitted by the \code{loess} (default) or \code{lm}/\code{glm} function (see the \code{resid.method.smooth} argument) where
  the confidence level band of the fitted/regression line can be controlled by the \code{level.cnfd} argument
  or by the \code{Value} output function \code{plot.rqq()} (and its \code{confidence} argument).

  \strong{Considerations to support or exclude model/fit based on the Q-Q plot, histogram and probability density.}
  If the residuals are assumed to be normally distributed, one can use a normal Q-Q (Quantile-Quantile) plot
  to check this assumption or its violation. Quantiles are often referred to as "percentiles". These are actually
  the data points, dividing the distribution into equal portions. For instance, for a 0.5 quantile (or the 2nd quartile),
  half of the data lie below this point and half of them above. This quantile is also referred to as \strong{median}.
  Similarly, the 0.25 quantile (or the 1st quartile) would mean, that \eqn{25\,\%} of the data fall below this point.
  Thus, the Q-Q plot presents quantiles from our sample (corresponding to residuals) related to the theoretical
  ones calculated for a specific distribution. For such purpose the \code{plot_eval_RA_forFit} function supports
  three residual distributions: the normal one, Student's t (including degrees of freedom, \code{df}) as well as the Cauchy one.
  If the points follow the diagonal line (or are not far from this line), we may describe our residuals by the specific
  distribution. Additionally, e.g. for normal "distro", the Q-Q plot can be also supported by the Shapiro-Wilk
  (\code{\link[stats]{shapiro.test}}) and/or by the Kolmogorov-Smirnov (\code{\link[stats]{ks.test}}) which are both included
  in the \code{\link{eval_ABIC_forFit}}. Therefore, the latter nicely works in combination with the actual function
  to get residuals characteristics (distribution) and consequently, to decide which model/fit is the best.
  Deviations from the diagonal/fitted line are also reflected in the histogram and probability density function/graph
  (PDF, providing the chances that the value of a random continuous variable will
  occur within a specific range of values). For the normal symmetric distribution it is represented by the bell-shaped
  curve with the maximum at the \strong{mean} (for residuals \eqn{= 0}, median = mean). Thus, the PDF basically
  corresponds to histogram with "extremely" high number of bins, having "extremely" small widths.
  A Q-Q plot may exhibit several basic
  \href{https://stats.libretexts.org/Bookshelves/Advanced_Statistics/Intermediate_Statistics_with_R_(Greenwood)/03\%3A_One-Way_ANOVA/3.04\%3A_ANOVA_model_diagnostics_including_QQ-plots}{deviations}.
  It can display a U-shaped pattern, which actually mirrors
  the situation with the right skewed (or positively skewed, mean > median) PDF. Therefore, we find the extreme
  values far from the peak on the high end more frequently than on the lower one (see e.g. \code{Example} in
  \code{\link{eval_kinR_Eyring_GHS}}). Contrary, if the Q-Q plot shows
  "hill" shape, the opposite situation is observed and the extreme values (outliers) far from the peak
  on the low end appear more frequently than on the higher one (PDF is left skewed, mean < median).
  Often, the heavy-tailed Q-Q plot with extreme residuals below and above minima and maxima of the diagonal line,
  respectively, may appear and is somewhat problematic for e.g. normal distributions of residuals with outliers on both sides.
  On the other hand, such kind of normality violation can be successfully described by Student's t-distribution
  with lower degrees of freedom (see e.g. \code{Examples} in the \code{\link{eval_sim_EPR_isoFit}}.
  Nevertheless, if the residuals, in the latter case,
  do not exhibit heteroscedasticity, such model/fit is not necessarily untrustworthy.
  In a very extreme case the heavy-tailed Q-Q plot may be transformed into situation where only a couple
  of points around the "middle" quantile can be found on the diagonal line and the remaining points are represented
  by the noticeable S-curve. This is reflected as bimodal behavior in the PDF and it might be the sign of a value clustering.
  The Q-Q plot (with "pointwise" confidence bands for the diagonal/fitted line, obtained by the \code{\link[MASS]{rlm}})
  in the actual function was built in the similar way like for the \href{https://github.com/aloy/qqplotr/}{\code{{qqplotr}}}
  package. The "pointwise" bands are based on the normal confidence intervals.
  The confidence level of those bands can be controlled by the \code{level.cnfd} argument
  or by the \code{Value} output function \code{plot.rqq()} (and its \code{confidence} argument).

  All the above-mentioned violations of the residuals (normal) distribution can disfavor our considered model/fit.
  However, one has to perform different diagnostic methods and tests to analyze the residuals in order to compare
  several models/fits and select the "best" one. Even in such case, this should be a compromise between
  the fit accuracy (fitting the data as well as possible, including the physico-chemical reality of the system)
  and the parsimony (using a simple and replicable model/fit, Kabacoff RI (2022) in the \code{References}).
}
\examples{
\dontrun{
## application example for an EPR simulation fit
list.test <-
  plot_eval_RA_forFit(
    data.fit = data.sim.expr,
    residuals = "Residuals",
    fitted = "Simulation",
    resid.xlab = "Simulation",
    k = length(optim.params.init),
    level.cnfd = 0.99
 )
#
## residual and the normal Q-Q plot
list.test$plot.rqq()
#
## residual and Q-Q plot for the Student's t distro
## with 4 degrees of freedom
list.test$plot.rqq(residuals.distro = "t",df = 4)
#
## histogram and probability density
list.test$plot.histDens
#
## standard deviation of residuals
list.test$sd
#
## from the data, quickly create the residuals vs
## observation order plot (assuming there
## is no index column in the data frame)
dataframe <- list.test$df
dataframe[["index"]] <- 1:nrow(dataframe)
plot(
  dataframe$index,
  dataframe$Residuals,
  xlab = "Observation Order",
  ylab = "Residuals"
)
#
## for additional examples, please,
## refer to the `eval_sim_EPR_isoFit`
## or `eval_kinR_EPR_modelFit`
#
}


}
\references{
Kabacoff RI (2022). \emph{R in Action}, 3rd edition, Manning Publications Co., ISBN 978-1-617-29605-5,
  \url{https://www.manning.com/books/r-in-action-third-edition}.

  Svetunkov I (2022). \emph{Statistics for Business Analytics}, Version 2025,
  \url{https://openforecast.org/sba/}.

  Hyndman RJ, Athanasopoulos G (2021). \emph{Forecasting: Principles and Practise}, 3rd edition,
  O Texts, ISBN 978-0-987-50713-6, \url{https://otexts.com/fpp3/}.

  Chugani V (2025). "The Concise Guide to Residual Analysis",
  \url{https://www.statology.org/concise-guide-residual-analysis/}.

  Boehmke B, Greenwell B (2020). \emph{Hand on Machine Learning with R}, 1st edition, Chapman and Hall/CRC,
  ISBN 978-1-138-49568-5, \url{https://bradleyboehmke.github.io/HOML/}.

  Kuhn M, Silge J (2023). \emph{Tidy Modelling with R}, 1st edition (Version 1.0.0), O'Reilly Media,
  ISBN 978-1-492-09648-1, \url{https://www.tmwr.org/}.

  Belzile L (2019). "lineaRmodels", \url{https://lbelzile.github.io/lineaRmodels/}

  James G, Witten D, Hastie T, Tibshirani R (2021). \emph{An Introduction to Statistical Learning:
  with Applications in R}, 2nd edition, Springer, ISBN 978-1-071-61417-4,
  \url{https://www.statlearning.com/}.

  Speegle D, Clair B (2021). \emph{Probability, Statistics and Data: A Fresh Approach Using R},
  1st edition (Version 2024), Chapman and Hall/CRC, ISBN 978-0-367-43667-4,
  \url{https://probstatsdata.com/}.

  The Pennsylvania State University (2018). "STAT 462 Applied Regression Analysis, Lesson 9: Influential Points",
  \url{https://online.stat.psu.edu/stat462/node/87/}.

  Nguyen M (2020). "A Guide on Data Analysis", \url{https://bookdown.org/mike/data_analysis/}.

  Gray JB, Woodal WH (1994). "The Maximum Size of Standardized and Internally Studentized Residuals in Regression Analysis",
  \emph{Am. Stat.}, \strong{48}(2), 111-113, \url{https://www.jstor.org/stable/2684258}.

  Frost J (2025). "Statistics by Jim: Making Statistics Intuitive", \url{https://statisticsbyjim.com/}.

  Kross S (2016). "A Q-Q Plot Dissection Kit", \url{https://seankross.com/2016/02/29/A-Q-Q-Plot-Dissection-Kit.html}.

  Walker JA (2020). "Normal Q-Q Plots - what is the robust Line and should we prefer it ?",
  \url{https://rdoodles.rbind.io/posts-biocstyle/2020-10-15-normal-q-q-plots-what-is-the-robust-line-and-should-we-prefer-it}.
}
\seealso{
Other Simulations and Optimization: 
\code{\link{eval_ABIC_forFit}()},
\code{\link{eval_sim_EPR_iso}()},
\code{\link{eval_sim_EPR_isoFit}()},
\code{\link{eval_sim_EPR_isoFit_space}()},
\code{\link{eval_sim_EPR_iso_combo}()},
\code{\link{optim_for_EPR_fitness}()},
\code{\link{plot_eval_EPRtheo_mltiplet}()},
\code{\link{quantify_EPR_Sim_series}()},
\code{\link{smooth_EPR_Spec_by_npreg}()}
}
\concept{Simulations and Optimization}
